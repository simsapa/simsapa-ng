use regex::Regex;
use lazy_static::lazy_static;
use serde::{Serialize, Deserialize};

use crate::helpers::latinize;

/// Represents a parsed PTS reference
/// Two formats supported:
/// - "D ii 20" → nikaya: "d", volume: Some("ii"), page: 20
/// - "Sn 52" → nikaya: "sn", volume: None, page: 52
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct PTSReference {
    pub nikaya: String,
    pub volume: Option<String>,
    pub page: u32,
}

/// Represents a single search result from the reference data
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ReferenceSearchResult {
    pub sutta_ref: String,
    #[serde(default)]
    pub title_pali: String,
    #[serde(default)]
    pub pts_reference: String,
    pub dpr_reference: Option<String>,
    pub dpr_reference_alt: Option<String>,
    pub url: String,
    // Parsed PTS reference fields for range matching
    // These can be null in the JSON
    pub pts_nikaya: Option<String>,
    pub pts_vol: Option<String>,
    pub pts_vol_verse: Option<String>,
    pub pts_start_page: Option<u32>,
    pub pts_end_page: Option<u32>,
    // Edition, e.g. Feer, Somaratne1999
    pub edition: Option<String>,
}

pub fn normalize_pts_reference(pts_ref: &str) -> String {
    let mut result = pts_ref.trim().to_lowercase();

    lazy_static! {
        static ref re_pts_punct: Regex = Regex::new(r#"[\.,;:\(\)~\u{00A0}]+"#).unwrap();
    }

    // Replace punctuation with space
    result = re_pts_punct.replace_all(&result, " ").into_owned();

    // Normalize multiple spaces to one
    result = result.split_whitespace().collect::<Vec<_>>().join(" ");

    // Remove range at the end (e.g., "209-213" becomes "209")
    // Look for a pattern like "number-number" at the end
    if let Some(last_space_idx) = result.rfind(' ') {
        let last_part = &result[last_space_idx + 1..];
        if let Some(dash_idx) = last_part.find('-') {
            let before_dash = &last_part[..dash_idx];
            // Check if before_dash is a number
            if before_dash.parse::<u32>().is_ok() {
                // Keep everything up to and including the space, plus the part before the dash
                result = format!("{} {}", &result[..last_space_idx], before_dash);
            }
        }
    }

    result.trim().to_string()
}

/// Parse a PTS reference string into components
/// Supports two formats:
/// - 3-part: "D ii 20" → nikaya: "d", volume: Some("ii"), page: 20
/// - 2-part: "Sn 52" → nikaya: "sn", volume: None, page: 52
///
/// Returns None if the string cannot be parsed
pub fn parse_pts_reference(pts_ref: &str) -> Option<PTSReference> {
    if pts_ref.trim().is_empty() {
        return None;
    }

    // Normalize: trim, lowercase, normalize whitespace
    let normalized = normalize_pts_reference(pts_ref);
    let normalized = normalized.split_whitespace().collect::<Vec<_>>().join(" ");

    let parts: Vec<&str> = normalized.split_whitespace().collect();

    if parts.len() < 2 {
        return None;
    }

    // First part should be the nikaya (one or more letters)
    let nikaya = parts[0];
    if !nikaya.chars().all(|c| c.is_alphabetic()) {
        return None;
    }

    // Try 3-part format first: nikaya + volume + page
    if parts.len() >= 3 {
        let volume = parts[1];
        // Check if second part is a roman numeral (volume)
        if volume.chars().all(|c| matches!(c, 'i' | 'v' | 'x')) {
            // Third part should be the page number
            if let Ok(page) = parts[2].parse::<u32>() {
                return Some(PTSReference {
                    nikaya: nikaya.to_string(),
                    volume: Some(volume.to_string()),
                    page,
                });
            }
        }
    }

    // Try 2-part format: nikaya + page (no volume)
    if parts.len() >= 2
        && let Ok(page) = parts[1].parse::<u32>() {
            return Some(PTSReference {
                nikaya: nikaya.to_string(),
                volume: None,
                page,
            });
        }

    None
}

/// Search by text in a specific field with normalization
/// Uses the latinize() function to remove diacritics for matching
pub fn search_by_text(query: &str, field: &str) -> Vec<ReferenceSearchResult> {
    if query.trim().is_empty() {
        return Vec::new();
    }

    let all_refs = crate::get_sutta_references();

    // Normalize query: lowercase and remove diacritics
    let normalized_query = latinize(&query.trim().to_lowercase());

    all_refs
        .iter()
        .filter(|entry| {
            let field_value_opt: Option<&str> = match field {
                "identifier" | "sutta_ref" => Some(&entry.sutta_ref),
                "name" | "title_pali" => Some(&entry.title_pali),
                "pts_reference" => Some(&entry.pts_reference),
                "dpr_reference" => entry.dpr_reference.as_deref(),
                "dpr_reference_alt" => entry.dpr_reference_alt.as_deref(),
                _ => None,
            };

            // Skip if field doesn't exist or is empty
            let field_value = match field_value_opt {
                Some(v) if !v.is_empty() => v,
                _ => return false,
            };

            let normalized_field = latinize(&field_value.to_lowercase());
            normalized_field.contains(&normalized_query)
        })
        .cloned()
        .collect()
}

/// Search by PTS reference with range matching support
/// Example: searching "D ii 20" will find the sutta that starts at "D ii 1"
/// if page 20 falls within the pts_start_page to pts_end_page range
pub fn search_by_pts_reference(query: &str) -> Vec<ReferenceSearchResult> {
    if query.trim().is_empty() {
        return Vec::new();
    }

    let parsed_query = match parse_pts_reference(query) {
        Some(p) => p,
        None => {
            // Fallback to text search if can't parse
            return search_by_text(query, "pts_reference");
        }
    };

    let all_refs = crate::get_sutta_references();

    let mut results: Vec<_> = all_refs
        .iter()
        .filter(|entry| {
            // Skip entries without nikaya
            let nikaya = match &entry.pts_nikaya {
                Some(n) => n,
                None => return false,
            };

            // Check if nikaya matches (case-insensitive)
            let nikaya_match = nikaya.to_lowercase() == parsed_query.nikaya;
            if !nikaya_match {
                return false;
            }

            // Check volume matching based on query and entry format
            match (&parsed_query.volume, &entry.pts_vol) {
                // Query has volume, entry has volume: must match
                (Some(query_vol), Some(entry_vol)) => {
                    if query_vol.to_lowercase() != entry_vol.to_lowercase() {
                        return false;
                    }
                }
                // Query has volume, entry doesn't: no match
                (Some(_), None) => return false,
                // Query has no volume, entry has volume: no match
                (None, Some(_)) => return false,
                // Both have no volume: continue to page matching
                (None, None) => {}
            }

            // Check if query page falls within the range
            match (entry.pts_start_page, entry.pts_end_page) {
                (Some(start), Some(end)) => {
                    // Page falls within start and end range (inclusive)
                    parsed_query.page >= start && parsed_query.page <= end
                }
                (Some(start), None) => {
                    // Only start page available, match if equal
                    parsed_query.page == start
                }
                _ => {
                    // No parsed page data
                    false
                }
            }
        })
        .cloned()
        .collect();

    // For 2-part format without volume (like "Sn 235" or "Th 627"),
    // also try treating it as a verse number using verse_sutta_ref_to_uid()
    // and append any verse matches to the results
    if parsed_query.volume.is_none() {
        // Construct a verse reference string like "Sn 235" or "Th 627"
        let verse_ref = format!("{} {}", parsed_query.nikaya, parsed_query.page);

        if let Some(uid) = crate::helpers::verse_sutta_ref_to_uid(&verse_ref) {
            // Search for this uid in the sutta_ref field
            let verse_results: Vec<_> = all_refs
                .iter()
                .filter(|entry| {
                    // Match the uid in sutta_ref (e.g., "snp2.1" or "Snp 2.1")
                    let sutta_ref_lower = entry.sutta_ref.to_lowercase().replace(' ', "");
                    let uid_lower = uid.to_lowercase();
                    sutta_ref_lower == uid_lower || sutta_ref_lower.starts_with(&format!("{}.", uid_lower))
                })
                .cloned()
                .collect();

            // Append verse results to existing results (avoiding duplicates)
            for verse_result in verse_results {
                if !results.iter().any(|r| r.url == verse_result.url) {
                    results.push(verse_result);
                }
            }
        }
    }

    // Sort results so that suttas starting at the exact page come first
    results.sort_by_key(|entry| {
        match entry.pts_start_page {
            Some(start) if start == parsed_query.page => 0, // Exact start page match
            Some(_) => 1, // Within range but not starting at this page
            None => 2,
        }
    });

    results
}

/// Universal search function that routes to appropriate search method
/// For 'pts_reference' field, uses range-based matching
/// For other fields, uses text-based matching
pub fn search(query: &str, field: &str) -> Vec<ReferenceSearchResult> {
    if field == "pts_reference" {
        search_by_pts_reference(query)
    } else {
        search_by_text(query, field)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_parse_pts_reference_valid() {
        let result = parse_pts_reference("D ii 20");
        assert!(result.is_some());
        let parsed = result.unwrap();
        assert_eq!(parsed.nikaya, "d");
        assert_eq!(parsed.volume, Some("ii".to_string()));
        assert_eq!(parsed.page, 20);
    }

    #[test]
    fn test_parse_pts_reference_with_extra_spaces() {
        let result = parse_pts_reference("  M   iii   10  ");
        assert!(result.is_some());
        let parsed = result.unwrap();
        assert_eq!(parsed.nikaya, "m");
        assert_eq!(parsed.volume, Some("iii".to_string()));
        assert_eq!(parsed.page, 10);
    }

    #[test]
    fn test_parse_pts_reference_two_part() {
        let result = parse_pts_reference("Sn 52");
        assert!(result.is_some());
        let parsed = result.unwrap();
        assert_eq!(parsed.nikaya, "sn");
        assert_eq!(parsed.volume, None);
        assert_eq!(parsed.page, 52);
    }

    #[test]
    fn test_parse_pts_reference_invalid() {
        assert!(parse_pts_reference("").is_none());
        assert!(parse_pts_reference("invalid").is_none());
        assert!(parse_pts_reference("abc").is_none()); // Just letters
    }

    #[test]
    fn test_latinize_normalization() {
        let query = "brahmajāla";
        let normalized = latinize(&query.to_lowercase());
        assert_eq!(normalized, "brahmajala");
    }

    #[test]
    fn test_json_loading() {
        // Initialize the global sutta references
        crate::init_sutta_references();

        let data = crate::get_sutta_references();
        assert!(data.len() > 0, "JSON data should be loaded and contain entries");

        // Print first entry for debugging
        if let Some(first) = data.first() {
            eprintln!("First entry: sutta_ref={}, pts_ref={}", first.sutta_ref, first.pts_reference);
        }
    }

    #[test]
    fn test_normalize_pts_reference_with_dots_tilde_and_range() {
        let result = normalize_pts_reference("D.~I. 13-45");
        assert_eq!(result, "d i 13");
    }

    #[test]
    fn test_normalize_pts_reference_with_trailing_dot() {
        let result = normalize_pts_reference("M.~II. 209-213.");
        assert_eq!(result, "m ii 209");
    }

    #[test]
    fn test_normalize_pts_reference_multiple_spaces() {
        let result = normalize_pts_reference("D   i    13");
        assert_eq!(result, "d i 13");
    }

    #[test]
    fn test_search_sn_verse_number() {
        // Initialize the sutta references database
        crate::init_sutta_references();

        // Test "Sn 235" which is a verse number, should find Snp 2.1
        let results = search_by_pts_reference("Sn 235");

        assert!(!results.is_empty(), "Should find results for Sn 235 (verse number)");

        // Should find Snp 2.1
        let found = results.iter().any(|r| {
            r.sutta_ref.to_lowercase().replace(' ', "") == "snp2.1"
        });
        assert!(found, "Should find Snp 2.1 when searching for verse Sn 235");
    }

    #[test]
    fn test_search_theragatha_verse() {
        crate::init_sutta_references();

        // Th 627 should map to Thag 12.2
        let results = search_by_pts_reference("Th 627");

        assert!(!results.is_empty(), "Should find result for Th 627 (Theragāthā verse)");

        // Check if thag12.2 is in the results
        let found = results.iter().any(|r| {
            let sutta_ref_lower = r.sutta_ref.to_lowercase().replace(' ', "");
            sutta_ref_lower.contains("thag12.2")
        });

        assert!(found, "Expected to find Thag 12.2 for verse Th 627");
    }

    #[test]
    fn test_search_therigatha_verse() {
        crate::init_sutta_references();

        // Thī 3 should map to Thig 1.3
        let results = search_by_pts_reference("Thī 3");

        assert!(!results.is_empty(), "Should find result for Thī 3 (Therīgāthā verse)");

        // Check if thig1.3 is in the results
        let found = results.iter().any(|r| {
            let sutta_ref_lower = r.sutta_ref.to_lowercase().replace(' ', "");
            sutta_ref_lower == "thig1.3"
        });

        assert!(found, "Expected to find Thig 1.3 for verse Thī 3, got: {:?}",
            results.iter().map(|r| &r.sutta_ref).collect::<Vec<_>>());
    }
}
